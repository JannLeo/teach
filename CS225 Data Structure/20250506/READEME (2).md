![image-20250509192310434](./READEME (2).assets/image-20250509192310434.png)

这张图解释了 **Bloom Filter 的错误率（False Positive Rate, FPR）**，重点是：在插入了 `n` 个元素之后，我们期望布隆过滤器的某一位被错误地判断为 “已存在” 的概率。

------

### 图中内容逐项解释如下：

#### 标题

- **Bloom Filter: Error Rate**：这是关于布隆过滤器误判率的公式推导。

------

### 公式部分：

我们关注的是：

> **某一位在插入 `n` 个对象之后，仍然是 1 的概率**

这代表了我们可能发生**假阳性（False Positive）**的概率，也就是你查询一个没插入过的元素，它却被判定“存在”的可能性。

------

#### 各变量含义：

- `m`：布隆过滤器的比特位总数（bit vector 的长度）
- `k`：哈希函数的数量
- `n`：插入的元素个数

------

### 正文黑体问题：

> **What is our expected FPR after n objects are inserted?**

我们的问题是：**插入 `n` 个对象后，误判率（FPR）是多少？**

------

### 蓝色文字：概率解释

> **The probability my bit is 1 after n objects inserted**

这个概率是：

$\left(1 - \left(1 - \frac{1}{m} \right)^{nk} \right)^k$

逐层解释：

1. **内层部分**：
   - $\left(1 - \frac{1}{m} \right)^{nk}$：表示某一位 **没有被任何一个哈希函数设置为 1** 的概率。
     - 每个插入元素用 `k` 个哈希函数，每次命中概率是 $\frac{1}{m}$
     - 总共 `nk` 次尝试
2. **外层部分**：
   - $1 - \text{上式}$：就是至少一次命中的概率（即变成1的概率）
3. **整体加上幂 `k`**：
   - 表示用 `k` 个哈希函数查询一个没插入过的元素时，**每个哈希函数对应的位都为 1** 的概率，也就是假阳性率。

------

### 右侧图示：

- 显示的是一个 Bloom Filter 比特向量，长度为 `m`
- 某个位置被标记为 1，代表它可能被若干哈希函数命中
- 使用的是 `k` 个哈希函数（底部标注 `h_{1,2,...,k}`）

------

### 橙色小字：

> **The number of [assumed independent] trials**

说明这个概率公式建立在：**每一次 hash 操作是独立的** 假设下。

------

### 总结：

这个公式是计算布隆过滤器误判率的核心，展示了它如何受到 `m`（位数组长度）、`k`（哈希函数数）、`n`（插入数）的影响。

是否需要我用这个公式举一个实际计算例子？

![image-20250509192600434](./READEME (2).assets/image-20250509192600434.png)

这张图是对前一页的延续，进一步探讨如何**最小化 Bloom Filter 的误判率（False Positive Rate, FPR）**，提出一个关键问题：

------

## **核心问题：**

> **To minimize the FPR, do we prefer…**
>  **(A) large k 还是 (B) small k？**

也就是说：**选择更多还是更少的哈希函数**，哪个更能降低误判率？

------

### 图中公式回顾：

$\left(1 - \left(1 - \frac{1}{m} \right)^{nk} \right)^k$

这是 FPR 的表达式。变量含义如下：

- `m`: Bloom Filter 的位数组长度
- `k`: 哈希函数数量
- `n`: 插入元素数量

------

## **k 的影响：**

我们用直觉来分析：

### 1. **当 k 较小时：**

- 每个元素只设置少数位，bit vector 中被置 1 的位较少。
- 查询时命中全部位的可能性较低，**误判率低**。

但也有可能：

- 太少的哈希函数 → 利用率不高 → 精度差。

------

### 2. **当 k 较大时：**

- 每个元素设置更多位 → bit vector 更容易“饱和”。
- 所有查询的哈希结果都命中为 1 的概率升高 → **误判率升高**！

------

## **那最佳值是多少？**

实际中有一个**最优的 k 值**，使误判率最低：

$k^* = \frac{m}{n} \ln 2$

也就是：给定 `m` 和 `n`，我们可以计算出最理想的哈希函数数量 `k`。这是下一页通常会介绍的内容。

------

### 图右侧补充：

- 是一个长度为 `m` 的 bit vector。
- 使用了 `k` 个哈希函数 `h₁, h₂, ..., hₖ`，每个用来设置一个 bit。

------

### 小结：

- 图中是引导学生思考：**哈希函数数量太多或太少都不是好事**。
- 我们要根据公式分析 FPR 和 `k` 的关系，最终找到 **最小化 FPR 的最优 k 值**。

------

是否需要我带你推导出最优 `k` 值的公式，或画个图展示它和误判率的关系？

![image-20250509192702587](./READEME (2).assets/image-20250509192702587.png)

这张图进一步解释了上两页提出的问题：**“选大的 k 还是小的 k 更能降低 Bloom Filter 的误判率？”**

------

## **左侧：A. 选择更大的 k**

### 数学含义：

表达式：

$\left(1 - \left(1 - \frac{1}{m} \right)^{nk} \right)^k$

- `k` 越大，`nk` 就越大 → 会使得整个 Bloom Filter 的 bit 被**快速填满**

- 所以整个表达式趋近于：

  (1−e−nk/m)k→1\left(1 - e^{-nk/m} \right)^k \to 1

- 导致 FPR（误判率）**趋近于 100%**

### 图中解释（红色）：

- 写着 “**FPR approaches 1**” 和 “≡ 100% FPR”
- 画了一个布隆过滤器示意图，全都是 `1`，表示**“bit vector 全部被占用了”**
- 这意味着：任何查询都会命中 `k` 个 1 → 会错误地认为元素存在

------

## **右侧：B. 选择较小的 k**

### 数学含义：

- 如果 `k` 太小，虽然 bit vector 比较稀疏，**不会太容易误判**
- 但缺点是：
  - hash 覆盖不够广 → 容易误判一些重复项
  - 整体效果仍然不好

图中蓝字解释：

- “As k decreases, this gets smaller!” 强调的是“FPR 可能变小”，但同时也要注意这不是无限下降的
- 蓝色图示中写了：
  - “Repeated random trials”：指的是我们可以看作每个哈希查询是一次独立试验
  - $FPR = (P)^k$：说明误判率是多个概率乘积，k 越小，次数越少 → 总概率降低

------

## **总结：**

- **k 太大 → bit vector 很快填满 → 误判率接近 100%**

- **k 太小 → 哈希函数少 → 每个查询信息不足，也可能导致误判率上升**

- **最优 k 值在中间**，即：

  k∗=ln⁡2⋅mnk^* = \ln 2 \cdot \frac{m}{n}

  这个值最小化 FPR，后续 PPT 通常会介绍这个推导。

------

是否要我帮你画图或解释一下这个最优 k 值的推导过程？

![image-20250509193035008](./READEME (2).assets/image-20250509193035008.png)

这张图是对 **Bloom Filter 最佳误判率（FPR）** 的推导，目标是找出 **最优哈希函数数量 `k\*`**。我们来详细解读每一部分：

------

## 一、目标：

> **To build the optimal hash function, fix `m` and `n`!**

我们想在 `m`（bit 向量长度）和 `n`（插入元素数量）固定的情况下，找到使误判率最小的 `k` 值。

------

## 二、关键结论：

$\boxed{k^* = \ln 2 \cdot \frac{m}{n}}$

这就是 **最优哈希函数数量的公式**。

- `ln 2 ≈ 0.693`，是自然对数常数
- 它告诉我们：**理想的哈希数量 k 与位图长度和元素个数有关**
- 右边蓝笔注释：
  - `k = hash` 函数个数
  - `M = BF size` 是布隆过滤器的位数
  - `n = items` 插入项数量
  - `α = n/m` 是负载因子（load factor）

------

## 三、公式推导过程：

### 原始 FPR 公式：

$\left(1 - \left(1 - \frac{1}{m}\right)^{nk}\right)^k$

这是布隆过滤器发生误判的概率。它很复杂，于是我们使用近似展开来简化它。

------

### 步骤 (1)：用自然指数函数逼近

使用 **泰勒展开** 得到：

$\left(1 - \left(1 - \frac{1}{m}\right)^{nk}\right)^k \approx \left(1 - e^{-nk/m}\right)^k$

右边红色注释指出，这个形式更容易微分、分析形状。

------

### 步骤 (2)：对近似表达式求导，寻找最小值

我们想让 FPR 最小，所以对误判率关于 `k` 的导数求导：

$\frac{d}{dk} \left(1 - e^{-nk/m}\right)^k \approx \frac{d}{dk} \left[k \cdot \ln(1 - e^{-nk/m})\right]$

这一技巧是常见的优化策略：**最小化 f(k) 就等价于最小化 ln(f(k))**，因为对数函数是单调的。

最终我们可以解出最小值出现在：

$k^* = \ln 2 \cdot \frac{m}{n}$

------

## 四、总结

这页 PPT 给出了**最优布隆过滤器设计的关键定理**：

- **最优哈希函数数量 k\*** 不固定，而是由 `m` 和 `n` 决定的
- 如果你知道要插入 `n` 个元素，准备了 `m` 个 bit，你就可以计算理想的哈希函数数量

------

是否需要我帮你做一个实际计算或画图演示 k 和 FPR 的关系？

![image-20250509193227740](./READEME (2).assets/image-20250509193227740.png)

这张图是对 Bloom Filter 最佳误判率推导中的 **Claim 1 的详细证明**，使用了指数函数和对数的性质来简化复杂表达式。我们逐行解释：

------

## **Claim 1 内容：**

$\left(1 - \left(1 - \frac{1}{m} \right)^{nk}\right)^k \approx \left(1 - e^{-nk/m} \right)^k$

也就是说：
 **布隆过滤器的误判率表达式可以近似为**：

从左边复杂的形式 → 右边使用指数函数的形式
 这样便于微分、分析和寻找最优值。

------

## **推导重点：底层用到的数学恒等式**

下面这行就是对中间那一块：

$\left(1 - \frac{1}{m} \right)^{nk}$

的处理方式：

$\left(1 - \frac{1}{m} \right)^{nk} = e^{\ln\left(\left(1 - \frac{1}{m} \right)^{nk}\right)} = e^{nk \cdot \ln(1 - 1/m)}$

这是指数与对数互换的基本性质：

- ![image-20250509193325762](./READEME (2).assets/image-20250509193325762.png)

这一步就是将幂转化为指数函数，用于数学推导简化。

------

## **为什么这样变形？**

- 为了简化表达式，将乘方变为指数，有利于微分。
- 因为：
  - 指数函数 `e^x` 的导数仍是 `e^x`，便于求最小值。
  - `ln(1 - 1/m)` 也能用泰勒展开进一步逼近。

------

## **下一步将近似：**

使用泰勒展开：

$\ln(1 - x) \approx -x \quad \text{当 } x \ll 1$

所以：

$\left(1 - \frac{1}{m} \right)^{nk} \approx e^{-nk/m}$

------

## **最终目标：**

将整个 FPR 公式：

$\left(1 - \left(1 - \frac{1}{m} \right)^{nk} \right)^k$

简化为：

$\left(1 - e^{-nk/m} \right)^k$

为下一步的优化和导数分析打下基础。

------

如你希望，我可以继续解释后续如何求导并得到最优哈希数 `k* = ln2·m/n`。是否继续？

![image-20250509193408225](./READEME (2).assets/image-20250509193408225.png)

这张图展示了布隆过滤器推导中的核心近似过程：**利用泰勒展开将幂函数近似为指数函数**。这是整个 FPR 公式简化的关键一步。我们来详细解释：

------

## 一、标题：

**Bloom Filter: Optimal Error Rate**
 这一页要说明为什么下面这个近似成立：

$\left(1 - \frac{1}{m} \right)^{nk} \approx e^{-nk/m}$

------

## 二、关键知识：泰勒展开（Mercator Series）

图中上方写的是自然对数的泰勒展开：

$\ln(1 + x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \cdots$

这是经典的 Mercator 级数展开，适用于 $|x| < 1$。

图中红色把二次项以后的部分都划掉了，表示我们**只保留第一项**来进行近似。

------

## 三、实际应用在布隆过滤器上

我们正在处理的表达式是：

$\left(1 - \frac{1}{m} \right)^{nk}$

取对数：

$\ln \left(1 - \frac{1}{m} \right) \approx -\frac{1}{m}$

因此：

$\left(1 - \frac{1}{m} \right)^{nk} = e^{nk \cdot \ln(1 - \frac{1}{m})} \approx e^{-nk/m}$

图中写了：

- $x = -\frac{1}{m}$，是小量

- 所以可以认为：

  ![image-20250509193723135](./READEME (2).assets/image-20250509193723135.png)

- 整个变换就是为了简化这个表达式，让它更容易求导和优化。

------

## 四、最终结论（图右下角黑框中的结论）

$\boxed{ \left(1 - \frac{1}{m} \right)^{nk} \approx e^{-nk/m} }$

这个近似成立的前提是：**m 很大、1/m 很小**，即 Bloom Filter 比特数组较长时是合理的。

------

## 总结一下：

- 本页完成了将复杂幂函数简化为指数函数的关键一步

- 接下来我们就能用这条近似结果，把布隆过滤器误判率公式写成：

  ![image-20250509193734486](./READEME (2).assets/image-20250509193734486.png)

  然后对它求导，得出最优哈希函数个数。

------

需要我继续解释如何根据这个近似值求导并找出最优 `k*` 吗？

![image-20250509193757025](./READEME (2).assets/image-20250509193757025.png)

这张图是对前面几页近似推导的最终收束，展示如何通过求导来找到 **使 Bloom Filter 的误判率最小的最优哈希函数数量 $k^\*$**。我们来逐步解释：

------

## 一、标题：Optimal Error Rate

> **目标**：对 Bloom Filter 的 FPR 近似表达式关于哈希函数数量 $k$ 求导，找出最优值。

------

## 二、Claim 2：求导步骤

我们已将误判率近似为：

$f(k) = \left(1 - e^{-nk/m} \right)^k$

这个形式不好直接求导，于是我们取对数，变成：

$\ln f(k) = k \cdot \ln(1 - e^{-nk/m})$

于是可以用链式法则求导：

$\frac{d}{dk} f(k) \approx \frac{d}{dk} \left[k \cdot \ln(1 - e^{-nk/m})\right]$

这是图中右上红笔圈出的公式。

------

## 三、数学技巧：导数规则

图中中间的公式是关键：

$\frac{d}{dx} \ln f(x) = \frac{1}{f(x)} \cdot \frac{df(x)}{dx}$

这是**对数函数的导数链式法则**，它让我们能先求 $\ln f(k)$ 的导数，然后再回到 $f(k)$ 上。

图中红笔注释：“Take deriv. of ln”，就是这个意思。

------

## 四、最小值结论（TL;DR）

图中说：

> \min f(x) = \min \ln f(x) ]

这在数学上是成立的（因为 $\ln(x)$ 是单调递增的），所以我们只要找 $\ln f(k)$ 的最小点，就等于找 $f(k)$ 的最小点。

------

## 五、最终结论：

> **导数为 0 时**，达到最小误判率的点：

$\boxed{k^* = \ln 2 \cdot \frac{m}{n}}$

这就完成了整个最优哈希数的推导过程！

------

### 小结：

- 使用指数近似和泰勒展开简化表达式
- 用链式法则求导
- 找到使导数为 0 的 $k$，即为最优解

------

如果你需要我进一步代入数字算一个实际例子（比如 m=1000, n=100），或者画图可视化 FPR 随 k 的变化，我也可以继续补充。是否需要？

非常好，我们来**详细推导出 Bloom Filter 的误判率最小时最优的哈希函数数量 $k^\*$**。这个过程包含如下几个步骤：

------

## **目标：**

最小化 FPR 近似表达式：

$f(k) = \left(1 - e^{-nk/m} \right)^k$

------

## **步骤 1：对数简化（取 ln）**

我们对 $f(k)$ 取自然对数（方便求导）：

$\ln f(k) = k \cdot \ln\left(1 - e^{-nk/m} \right)$

------

## **步骤 2：对上式求导**

记住：我们现在是要求导数 $\frac{d}{dk} \ln f(k)$，再让它等于 0 来找最小值。

使用积的求导法则：

$\frac{d}{dk} \left[ k \cdot \ln\left(1 - e^{-nk/m} \right) \right] = \ln\left(1 - e^{-nk/m} \right) + k \cdot \frac{d}{dk} \ln\left(1 - e^{-nk/m} \right)$

现在我们来算第二项：

------

## **步骤 3：链式法则继续求导**

我们有：

$\frac{d}{dk} \ln\left(1 - e^{-nk/m} \right) = \frac{1}{1 - e^{-nk/m}} \cdot \frac{d}{dk} \left(1 - e^{-nk/m} \right)$$= \frac{1}{1 - e^{-nk/m}} \cdot \left( 0 - \left( \frac{n}{m} \cdot e^{-nk/m} \right) \right) = - \frac{n}{m} \cdot \frac{e^{-nk/m}}{1 - e^{-nk/m}}$

------

## **步骤 4：代入回总导数表达式**

$\frac{d}{dk} \ln f(k) = \ln\left(1 - e^{-nk/m} \right) - \frac{nk}{m} \cdot \frac{e^{-nk/m}}{1 - e^{-nk/m}}$

令导数为 0：

$\ln\left(1 - e^{-nk/m} \right) = \frac{nk}{m} \cdot \frac{e^{-nk/m}}{1 - e^{-nk/m}}$

这是一个复杂的方程，不容易代数上解出。但我们可以通过数值方式或图像观察最小点在哪。

------

## **步骤 5：用近似和数学分析得到结论**

使用数学推导（例如使用极值点、导数二阶分析等方法）可以得出：

$k^* = \ln 2 \cdot \frac{m}{n}$

这是已知的数学最优解，在实际中被广泛采用。

------

## **结论：**

只要你知道：

- $m$：布隆过滤器 bit vector 的总长度
- $n$：要插入的元素个数

你就可以算出**最优哈希函数数量**：

$\boxed{k^* = \ln 2 \cdot \frac{m}{n} \approx 0.693 \cdot \frac{m}{n}}$

------

## **例子：**

假设：

- $m = 1000$（1000 位 bit 向量）
- $n = 100$（插入 100 个元素）

则：

$k^* = \ln 2 \cdot \frac{1000}{100} = 0.693 \cdot 10 \approx 6.93 \approx 7$

**最优选择是 7 个哈希函数。**

------

如果你想，我可以画图展示误判率随 $k$ 变化的曲线，帮助你更直观地理解这一结论。需要吗？

![image-20250509194214147](./READEME (2).assets/image-20250509194214147.png)这张图以图像方式直观展示了我们刚才推导的布隆过滤器最优误判率（FPR）点是如何得到的。下面是详细解释：

------

## **图表左侧公式：**

误判率 FPR 的近似公式为：

$\text{FPR} \approx \left(1 - e^{-nk/m}\right)^k$

这是我们之前几页推导出的核心公式。

------

## **图表说明：**

- 横轴（x轴）：**哈希函数数量 $k$**，从 4 到 9 个
- 纵轴（y轴）：**误判率 FPR**
- 图中展示了不同 $k$ 值下 FPR 的变化趋势，形成一个 **U 型曲线**

------

## **红色分析：**

- **左侧**：$k$ 太小 → FPR 较高
  - 注解写着：**“Not enough random trials”**
  - 原因：哈希函数太少，每个元素只设置少数几位，容易“撞车”
  - 布隆过滤器的能力未被充分利用
- **右侧**：$k$ 太大 → FPR 也升高
  - 注解写着：**“BF becomes too saturated with 1s”**
  - 原因：太多哈希函数使得 bit 向量被大量填充为 1
  - 结果是几乎所有位置都为 1，查询任意值几乎都误判“存在”

------

## **最优点标注：**

- 红色箭头指出最小点在：

  k∗=ln⁡2⋅mn=ln⁡2⋅10≈6.93k^* = \ln 2 \cdot \frac{m}{n} = \ln 2 \cdot 10 \approx 6.93

- 图中曲线最低点正好在 $k \approx 7$，验证了理论推导的结果

------

## **右上角说明 `m/n = 10`**

- 表示：
  - Bit vector 长度是元素数量的 10 倍
  - 是布隆过滤器设计中的一个“负载因子”
- 这个比例常用于实际部署

------

## **右侧图示：**

- 一个小框图表示 bit 向量中大量位置被设置成 1（饱和），意味着误判率趋近于 1

------

## **总结：**

- 图像 **完美验证** 数学推导结果

- **FPR 随着哈希函数数量 $k$** 先下降后上升 → 存在最优点

- 我们通过数学推导得出：

  k∗=ln⁡2⋅mnk^* = \ln 2 \cdot \frac{m}{n}

  并通过图像进一步直观确认了这一点

------

如你需要，我可以帮你制作一个交互图表（用你自己的参数）或用 Python 画出不同 m/n 比下的 FPR 曲线图。需要吗？

![image-20250509195304020](./READEME (2).assets/image-20250509195304020.png)

这张图总结了 Bloom Filter 中三个关键参数的关系，并展示了如何通过已知两个参数来计算第三个。我们来详细分析：

------

## 一、核心公式：

$\boxed{k^* = \ln 2 \cdot \frac{m}{n}}$

- $k^*$：最优哈希函数数量（为了最小化误判率）
- $m$：布隆过滤器的 bit 向量长度（单位：bit）
- $n$：插入元素个数

> **只要知道其中两个参数，就可以计算出第三个。**

------

## 二、逐个案例解释

------

### **第一行：求 $m$**

- 已知：$n = 100$，$k = 3$
- 用公式反推：

$m = \frac{k \cdot n}{\ln 2} = \frac{3 \cdot 100}{0.693} \approx 433 \text{ bits}$

也就是说，为了在插入 100 个元素、使用 3 个哈希函数时达到最优，bit 向量需要至少 433 位。

------

### **第二行：求 $k$**

- 已知：$m = 100$，$n = 20$
- 代入公式：

$k = \ln 2 \cdot \frac{m}{n} = 0.693 \cdot \frac{100}{20} = 3.465 \approx 3.5$

可以选择四个哈希函数，更接近最优点。

------

### **第三行：求 $n$**

- 已知：$m = 100$，$k = 2$
- 反推：

$n = \frac{m \cdot \ln 2}{k} = \frac{100 \cdot 0.693}{2} \approx 34.65 \approx 35 \text{ items}$

所以当我们希望只用 2 个哈希函数，并希望保持最优误判率，插入元素应控制在 35 个以内。

------

## 三、总结记忆方式：

| 已知       | 求解公式                      |
| ---------- | ----------------------------- |
| $n$ 和 $k$ | $m = \frac{k \cdot n}{\ln 2}$ |
| $m$ 和 $n$ | $k = \ln 2 \cdot \frac{m}{n}$ |
| $m$ 和 $k$ | $n = \frac{m \cdot \ln 2}{k}$ |

------

这张图展示的非常实用：**如何在资源受限的系统设计中做权衡取值**。

是否需要我提供一个 Excel 表格或 Python 脚本，方便你自由输入两个参数快速计算第三个？

![image-20250509195355287](./READEME (2).assets/image-20250509195355287.png)

这张图是 Bloom Filter 最佳参数选择在真实大规模应用中的一个**实践案例分析**，以 “1000 Genomes Project” 为例进行估算，展示了 Bloom Filter 的惊人节省空间能力。我们分解解释如下：

------

## 一、上方公式（重点）

$\boxed{m = \frac{n \cdot k}{\ln 2} \approx 1.44 \cdot n \cdot k}$

含义是：为了实现最佳误判率，**bit 向量长度 `m` 应该约等于 1.44 倍的 `n·k`**

------

## 二、红笔说明解析

### **右上角标注**

- “Optimal hash function is still O(1)!”：即便要使用多个哈希函数，复杂度仍然是常数级，不影响性能。
- “Don’t need to be optimal!”：在实际系统中，**哪怕不是最优参数，只要在合理范围内，Bloom Filter 效果仍然很好。**

------

## 三、实际例子分析：

### **场景：1000 Genomes Project**

- `n = 250,000 files` （估计的基因样本或文件数）
- 数据规模 `≈ 10^{15}` nucleotides（核苷酸序列数量）
- 原始数据大小：**260 TB**

------

### **我们用 Bloom Filter 来索引这些文件：**

用公式估算 bit 向量所需大小：

- 设 $k = 1$ 或 $k = 2$

- 使用：

  m≈1.44⋅n⋅km \approx 1.44 \cdot n \cdot k

- 带入 $n = 250,000$：

#### 当 $k = 1$：

$m = 1.44 \cdot 250,000 \approx 360,000 \text{ bits} ≈ 45 \text{ KB}$

#### 当 $k = 2$：

$m ≈ 720,000 \text{ bits} ≈ 90 \text{ KB}$

所以：

- **只用 45–90 KB 就能代表 260 TB 的数据文件集合索引信息！**
- 布隆过滤器用于“快速判断某个文件是否可能存在”，非常高效。

------

## 四、底部说明：

- **搜索词“cat photos”** 引出了另一个场景：海量网页图像也可以用布隆过滤器表示。
- 提到了：
  - `n = 60 billion ~ 130 trillion`：Google 网页总量（Bloom Filter 可用于 URL 黑名单、安全检测等）

------

## 五、总结：

| 对比项   | 原始存储                         | Bloom Filter                          |
| -------- | -------------------------------- | ------------------------------------- |
| 大小     | 260 TB                           | 45–90 KB                              |
| 精度     | 有一定误判（可控）               | 有误判但**无漏判**（One-sided error） |
| 应用场景 | 文件存在性检测、搜索索引、黑名单 | 极其适合大规模系统索引和检测          |

------

如你感兴趣，我可以继续用 Python 模拟“指定误判率下如何选择 m 和 k”，或将它写成 Excel 模板方便调整，是否需要？

![image-20250509195516561](./READEME (2).assets/image-20250509195516561.png)

这张图是对 Bloom Filter 的**关键概念与误判率公式**的总结，内容精炼、概括性强。我们来逐条解释：

------

## **一、标题：Bloom Filters**

说明 Bloom Filter 是：

> **A probabilistic data structure storing a set of values**

它是一种**概率性数据结构**，用来表示一个集合，可以高效判断某元素是否“可能存在”或“一定不存在”。

------

## **二、三个关键参数：**

1. **$k$** — 哈希函数数量
   - 每个插入元素通过 $k$ 个哈希函数映射到 $k$ 个 bit 位
2. **$n$** — 插入的元素数量
   - 是你计划往 Bloom Filter 中加入的项目个数
3. **$m$** — bit 向量的总长度（单位：bit）
   - 决定了 Bloom Filter 的总内存空间

------

## **三、误判率公式：**

### 精确表达：

$\left(1 - \left(1 - \frac{1}{m} \right)^{nk} \right)^k$

解释：

- $\left(1 - \frac{1}{m} \right)^{nk}$：表示一个 bit 没被设置为 1 的概率
- 外面再取 $1 - (\cdot)$：表示某个 bit 被设置成 1 的概率
- 然后整个表达式的 $k$ 次方：表示查询一个元素时，**所有 k 个位置都为 1** 的概率，即 **误判率 FPR**

### 指数近似：

$\left(1 - e^{-nk/m} \right)^k$

这是前几页推导中使用泰勒展开后的近似形式，便于进一步分析。

------

## **四、最优准确率条件：**

$\boxed{k^* = \ln 2 \cdot \frac{m}{n}}$

含义：

- 当哈希函数数量取这个值时，误判率最低
- 是整个布隆过滤器设计中最重要的公式之一
- 已在多页图中被推导验证

------

## **五、右侧图示：**

- 一个纵向 bit 向量，总共 $m$ 位
- 右上标注 $h_{\{1,2,...,k\}}$：表示有 $k$ 个哈希函数来控制它
- 上方的计时器图标暗示 Bloom Filter 查询非常快（**常数时间 O(k)**）

------

## **总结：**

这页是对你整套 Bloom Filter 学习的高度概括：

| 概念       | 公式/含义                          |
| ---------- | ---------------------------------- |
| FPR        | $\left(1 - e^{-nk/m} \right)^k$    |
| 最优哈希数 | $k^* = \ln 2 \cdot \frac{m}{n}$    |
| 参数关系   | 只需设定两个参数，另一个可以反推出 |
| 结构性质   | 占用少，查询快，误判但无漏判       |

------

如果你需要我帮你把这些公式/关系整理成一个可打印的公式卡片或知识图谱，我也可以制作。是否需要？

![image-20250509195604257](./READEME (2).assets/image-20250509195604257.png)

这张图展示了 **Bloom Filter 在网站缓存（website caching）中的实际应用**，并强调了它在高性能系统中的价值。以下是详细解读：

------

## 一、应用场景：网站缓存策略

图中浏览器（Chrome 图标）在访问一个页面前会问：

> **“Loaded this before?”**

于是它用布隆过滤器判断页面是否**可能**已经被访问过。

------

## 二、两种情况：

### **1. 查询命中（可能访问过）**

- 图右侧提示：**“Cache this page!”**
- 表示：布隆过滤器判定该页面“可能已访问过”
- 实际处理策略：**缓存这个页面（通常是第二次访问时）**

手写说明：

- “Cache on 2nd visit”
- “Sometimes on first” → 即偶尔第一次访问时也缓存

### **2. 查询未命中（一定没访问过）**

- 图右侧蓝箭头：**“Add to filter (but don’t cache!)”**
- 表示：页面第一次被访问，先加入布隆过滤器，但**不立刻缓存**

------

## 三、布隆过滤器的作用：

### **优点：**

- **节省磁盘写入次数**
- 减少缓存写入负担，过滤掉只访问过一次的页面（不值得缓存）

图中下方折线图：

- y 轴：Disk writes per second（每秒磁盘写入次数）
- 横轴时间轴显示：布隆过滤器开启之后，磁盘写入负载明显下降
- 图中红字标注：“Bloom filter turned on” → 说明效果显著

------

## 四、误判不是问题！

图右上角红字说明：

> **“False positive is not a problem!”**

意思是：

- 就算 Bloom Filter 错误地认为“该页面访问过”（实际没访问过）
- 最多就是提前缓存了一次 → **缓存了几个额外页面不是坏事！**

手写备注补充：

- “Caching a few extra pages isn’t bad”

------

## 五、总结：这个策略的核心思路是

| 请求阶段 | Bloom Filter判断     | 动作             |
| -------- | -------------------- | ---------------- |
| 首次访问 | 不存在（肯定）       | 不缓存，只加入BF |
| 后续访问 | 可能存在（可能误判） | 缓存该页面       |

这种“缓存第二次访问的页面”的策略在 CDN、内容分发网络中非常常见。

------

## 六、引用来源：

右下角引用了论文：

> Maggs, Bruce M., and Ramesh K. Sitaraman.
>  *Algorithmic nuggets in content delivery*, ACM SIGCOMM CCR, 2015.

这说明这个策略是**经过业界实际应用验证的技术**。

------

如果你想，我可以帮你用这个思路写一个简易 Python 示例或伪代码，演示如何在缓存系统中集成 Bloom Filter。是否需要？

![image-20250509195959810](./READEME (2).assets/image-20250509195959810.png)

这张幻灯片讨论的是：**在 C++ 中如何实现一个 bit 向量（bit vector）**，也就是布隆过滤器使用的底层结构。以下是逐部分详细解释：

------

## 一、标题：Bitwise Operators in C++

说明我们关注的是 C++ 中用**按位操作（bitwise operators）**来构建和处理位向量。

------

## 二、问题：如何用 C++ 表示 bit vector？

> “**How can we encode a bit vector in C++?**”

也就是：在不浪费内存的前提下，如何构造一个 **m 位的数组（bit array）**。

------

## 三、常见方式分析

图中用红色与蓝色笔手写说明：

### **方法一：`vector<bool>`**

- 语法简洁，但有个隐藏问题：
  - `vector<bool>` 是 C++ 标准库中的**特化模板**，不是实际的向量容器
  - **不是线程安全的（can't be multi-threaded）**
  - **不能正确实现 vector 的特性**（如指针访问、引用赋值等）

图中蓝笔写着：

> ```
> vector<bool>` doesn't make vector
>  `→ can't be multi-threaded`
>  `→ doesn't implement parts of vector
> ```

------

### **方法二：用 `char` 或 `uint8_t` 表示每 8 个 bit**

- 1 byte = 8 bits，可将 bit vector 映射到一个 `char` 数组中
- 图中写着：
  - `char = 8 bits`
  - `uint8_t = 8 bits`
- 比如：
  - 你要查找第 3 位，就需要取出该字节，再用位掩码提取对应位置

底部红色二进制图展示了 bit 向量分布，每 8 个 bit 对应一个字节（char）

------

## 四、问题与挑战

图中蓝笔写着：

> “None are particularly good”
>  “Work w/ extra steps”

即：

- 无论是 `vector<bool>` 还是自己处理 `char[]`，都不理想
- 需要用**手动位操作**（bit shifts, masks）来模拟，增加复杂度

------

## 五、例子说明

图下方红笔演示了如何查找第 3 个 bit（从 0 开始）：

```
bit index:      0 1 2 [3] 4 5 6 7
bit values:     1 0 1 0 1 0 1 0
→ lookup entire char
```

要提取某个位，必须从整个字节中“掩码+移位”提取。比较繁琐。

------

## 六、小结：

| 方法                    | 优点           | 缺点/注意事项                       |
| ----------------------- | -------------- | ----------------------------------- |
| `vector<bool>`          | 语法简单，常用 | 特化类型，不是真 vector；线程不安全 |
| `char[]` 或 `uint8_t[]` | 可精确控制内存 | 需要手动做位操作，代码复杂          |

------

### **推荐：**

- 如果写布隆过滤器核心代码，**推荐用 `uint8_t[]` 或 `std::bitset`（若大小固定）**
- 结合按位操作 `|`, `&`, `~`, `<<`, `>>` 来处理每一位

------

是否需要我给你一个简单示例代码：比如用 C++ 实现 `setBit`, `getBit`, `clearBit` 操作函数？

![image-20250509203422518](./READEME (2).assets/image-20250509203422518.png)

这张幻灯片说明了 **C++ 中 bit vector 的位顺序读取习惯**，并指出了一个重要的**陷阱警告**：你在 Lab_Bloom 中读取位时不要按照“从右到左”的传统方式理解。以下是详细解析：

------

## 一、传统习惯：从右到左读取位

标题下方红字说明：

> **Traditionally, bit vectors are read from RIGHT to LEFT**

也就是说：二进制通常被解释为：

- **最低位在最右边**（bit 0）
- **最高位在最左边**（bit 7）

------

## 二、例子一（第一行 bit 向量）

位序列是：

```
0 0 0 0 1 1 1
```

红笔标记了每一位的权重（从右往左）：

```
64 32 16 8 4 2 1
```

非零位是 4、2、1，对应的值相加：

$1 + 2 + 4 = 7$

------

## 三、例子二（第二行）

位序列是：

```
1 0 0 0 1 0 1 0
```

从右到左依次赋权：

$1\cdot64 + 1\cdot8 + 1\cdot2 = 64 + 8 + 2 = 74$

------

## 四、核心警告：

> **Warning: Lab_Bloom won’t do this**

这意味着你在课程或实验 Lab_Bloom 中不应该**默认 bit 是从右往左解释的**！

### 可能原因：

- 自定义实现中 bit vector 是按 **顺序（从左到右）** 存储或读取的
- 也可能是因为 `std::vector<bool>` 或 `std::bitset` 实现中的特殊行为

------

## 五、总结：

| 项目             | 传统二进制表示       | Lab_Bloom 可能做法       |
| ---------------- | -------------------- | ------------------------ |
| 读取顺序         | 从右到左（低位在右） | 自定义方向（可能反过来） |
| 权重计算方式     | $2^0, 2^1, ...$      | 不一定按此顺序           |
| 编程时的注意事项 | 要小心位偏移、掩码   | 明确实现顺序逻辑         |

------

如果你想，我可以帮你写一个小函数来：
 1）展示如何从左/右方向解释 bit 序列
 2）或者帮你写 bit vector 访问器模板（适配 Lab_Bloom）

需要吗？

![image-20250509203608905](./READEME (2).assets/image-20250509203608905.png)

这张幻灯片是 **C++ 中常见按位运算符（bitwise operators）示例解析**，讲解非常清晰，并配有图示。下面是详细解读：

------

## **一、变量定义**

- `A = 10110`
- `B = 01110`

我们假设这两个是 5 位无符号二进制数，从左到右分别是高位（MSB）到低位（LSB）。

------

## **二、操作符解释与结果**

### 1. **按位取反（~）**

```
~B = 10001
```

说明：

- 将所有位**1 变 0，0 变 1**
- 注释：“invert all 1s and 0s”

------

### 2. **按位与（&）**

```
A & B = 00110
```

说明：

- 只有对应位 **都为 1，结果才是 1**，否则为 0
- 例：
  - A: `1 0 1 1 0`
  - B: `0 1 1 1 0`
  - 逐位与：`0 0 1 1 0`

注释：“Both have to be 1 for 1, else 0”

------

### 3. **按位或（|）**

```
A | B = 11110
```

说明：

- 只要有一个为 1，就输出 1
- 注释：“If either is 1, set 1, else 0”

------

### 4. **右移（A >> 2）**

```
A >> 2 = 00101
```

说明：

- 将 A 向右移两位（低位移出，高位补 0）
- 原始 A: `10110`
- 右移两位后：`00101`

注释：“discard least sig bits & replace most w/ 0”

------

### 5. **左移（B << 2）**

```
B << 2 = 11000
```

说明：

- 将 B 向左移两位（高位移出，低位补 0）
- 原始 B: `01110`
- 左移后：`11000`

注释：“discard most sig bits & replace least w/ 0”

------

## **三、图中蓝色小注释说明**

- 指出 **位 3 是否为 1**，与逻辑表达如 `B & 00100` 配合使用判断特定位状态
- `00100` 是一个掩码（mask）值，用来测试 B 的第 3 位（从右数第 3 位）

------

## **四、小结**

| 操作 | 名称     | 含义与用途                |
| ---- | -------- | ------------------------- |
| `~`  | 按位取反 | 所有位取反                |
| `&`  | 按位与   | 掩码测试、清零等          |
| `    | `        | 按位或                    |
| `>>` | 右移     | 除以 2 的幂，或向低位移动 |
| `<<` | 左移     | 乘以 2 的幂，或向高位移动 |

------

如果你想，我可以写一个简单的 C++ 程序，把这些操作都演示出来，并附带注释帮助你练习理解。需要吗？

![image-20250509203709737](./READEME (2).assets/image-20250509203709737.png)

这张幻灯片讨论的是布隆过滤器（Bloom Filter）在**数据集合合并（Union）或交集（Intersection）时的意义与优势**，特别强调了：

> **使用 Bloom Filter 合并（而不是直接合并数据集）可以极大提升效率与节省空间。**

以下是逐点详细解析：

------

## 一、问题导向：

> **What is the conceptual meaning behind union and intersection?**

我们要理解的是：两个数据集的合并（或交集）在 bit vector 层面上是如何表示的。

------

## 二、例子结构（图解说明）

### 左边：两个数据集

- `Dataset A` 和 `Dataset B` 分别表示两个原始集合
- 使用相同的哈希函数将其分别构建成两个 Bloom Filter（BF）
  - BF_A
  - BF_B
- 图中写着：“**have same hash function**” 是合并的必要条件

------

## 三、合并方式对比：

### 方法一：**直接合并原始数据集**

- 即：`C = A ∪ B`
- 然后对 `C` 再建一个新的 Bloom Filter

图中红字评论：

- **“union datasets”**
- **“slow!”**
- **“Big!”**
- **“Bad!”**

这是最慢也最浪费空间的方法，因为原始数据集通常很大。

------

### 方法二：**合并 Bloom Filter 本身**

- 利用位操作 `bitwise OR`：

  BFC=BFA ∣ BFB\text{BF}_C = \text{BF}_A \, | \, \text{BF}_B

- 每个位：只要 A 或 B 的某个位为 1，合并后的该位就是 1

图中写着：

- **“union BF”**
- **“fast”**
- **“small”**
- **“good”**
- 最终：“same filter at end!”

------

## 四、交集（intersection）也可以实现：

虽然图中主讲 union，但实际上：

- 交集可通过 `bitwise AND`：

  BFC=BFA & BFB\text{BF}_C = \text{BF}_A \, \& \, \text{BF}_B

- 可用于**快速排除非共有元素**

------

## 五、总结：

| 方法              | 操作对象      | 优点         | 缺点               |
| ----------------- | ------------- | ------------ | ------------------ |
| 合并原始数据集    | Dataset A ∪ B | 精确         | 慢、耗内存         |
| 合并 Bloom Filter | BF_A \| BF_B  | 快、占内存小 | 存在误判（可容忍） |

------

这个技巧在搜索引擎、数据库索引、网络黑名单合并中非常实用。

如果你想，我可以举个具体例子（两个集合如何转化成 BF 并合并），或提供 Python 演示代码。需要吗？

![image-20250509203859373](./READEME (2).assets/image-20250509203859373.png)

这张幻灯片是引出 **Sequence Bloom Trees (SBT)** 的动机，用于解决在**大量生物序列文件中高效搜索目标序列**的问题。我们逐一解析：

------

## 一、背景场景

> **“Imagine we have a large collection of text…”**

- 这些文本文件包含的是类似 DNA 的字符串（如：`ATGTTGAATTAACCCGG...`）
- 每个文件中可能包含数千到数百万条生物序列

------

## 二、目标

> **“And our goal is to search these files for a query of interest…”**

也就是说：

- 我们想检查一个**查询字符串是否存在于这些文件中**
- 查询可能是某一段 DNA 子串，比如：“ACCGGTTAA”

------

## 三、问题挑战

如果你逐文件暴力搜索（brute-force）：

- 成本高（每次都要加载文件）
- 慢（尤其是海量数据时）

------

## 四、动机：用布隆过滤器加速查询

幻灯片中绿色的文件表示：

- 使用某种结构提前为每个文件构建索引
- 只搜索可能命中的文件
- 跳过一定“不可能命中”的文件（即 Bloom Filter 判断为不存在）

这就引出了接下来的 **SBT**：

------

## 五、Sequence Bloom Tree 的核心思想（预告）

- 为每个文件构建一个布隆过滤器，表示它可能包含的 k-mer（固定长度子串）
- 然后把这些 Bloom Filters 组织成树状结构
- 查询时只需走**可能匹配路径**

------

## 六、总结：这页幻灯片的逻辑链

| 元素             | 含义                                              |
| ---------------- | ------------------------------------------------- |
| 一堆文件         | 每个是一个生物数据集                              |
| 文件中的绿色文本 | DNA 序列，后面会被切成 k-mer 存入 Bloom Filter    |
| 搜索目标         | 想找某个子串是否存在于某些文件                    |
| 多个绿色文件     | 说明它们是**可能匹配的文件**，提前被标记/筛选出来 |

------

如果你想，我可以帮你进一步解释接下来的 SBT 是怎么构建与查询的，或者帮你写个模拟 SBT 查询流程的代码。要继续吗？

![image-20250509210916506](./READEME (2).assets/image-20250509210916506.png)

这张图解释的是**基数估计（Cardinality Estimation）**的一个基本思想，用于估计集合中不重复元素的个数。

我们来逐行详细解释：

------

### 【标题】

**Cardinality Estimation**：
 基数估计，即估算某个集合中有多少个**唯一元素**（distinct elements），是大数据处理中常用的技术。

------

### 【正文】

**Imagine we have a SUHA hash h over a range m.**
 假设我们有一个 **SUHA 哈希函数** `h`，它将元素映射到区间 `[0, m-1]` 上。

- SUHA 全称是 **Simple Uniform Hashing Assumption（简单均匀哈希假设）**，意思是：每个输入值 `x` 被哈希函数 `h(x)` 映射到 `[0, m-1]` 之间是等概率的。

------

**Inserting a new key is equivalent to adding a card to our hat!**
 插入一个新元素，相当于往“帽子”里加一张牌。

- 这是一个比喻：我们往哈希函数中输入键（key），就像往帽子里放卡片。

------

**Tracking only the minimum value is a sketch that estimates the cardinality!**
 只追踪**最小的哈希值**，就可以作为一种“sketch”来估计基数。

- **Sketch**：一种空间高效的数据摘要结构。
- 原理：如果你把许多元素哈希到 `[0, m-1]`，并只记录最小的哈希值 `min(h(x))`，那么根据概率统计知识，就可以用这个最小值反推出大致有多少不同的元素。

------

### 【下方图示】

图中画了一个三角形，表示哈希值的范围：

- 左端是 `0`，右端是 `m - 1`，顶部是某个 `h(x)` 值。
- 灰色区域表示可能的哈希结果，蓝色底部区域强调**我们关注的只是最小值**。

------

### 【总结】

这张图讲述了基于 SUHA 哈希、只记录哈希最小值（或最大值、稀疏值）来进行**基数估计**的基本思路。这种方法属于**概率算法**，代表性的算法有：

- **MinCount**
- **LogLog**
- **HyperLogLog**

它们可以在 **不存储全部数据的情况下**，快速且节省内存地估计集合的大小。

------

需要我补充数学公式推导或者举个实际例子说明吗？

![image-20250509211515810](./READEME (2).assets/image-20250509211515810.png)

这张幻灯片继续讲解**基数估计（Cardinality Estimation）**，在上一张图的基础上进一步引入了“归一化哈希”的概念。以下是逐句和图示的详细中文解释：

------

### 标题：Cardinality Estimation（基数估计）

------

### 第一部分（重复前面内容，便于上下文连贯）

- **假设我们有一个 SUHA 哈希函数 h，它的输出范围是 [0, m-1]。**
- **每插入一个新的 key，相当于往帽子里丢一张卡片。**
- **如果我们只追踪这些哈希值中的最小值，它就构成了一个 sketch，可用于估计元素数量。**

------

### 新内容部分：

#### “To make the math work out, let’s normalize our hash…”

“为了便于数学推导，让我们对哈希值做归一化处理……”

也就是说，我们将原始的哈希值 `h(x)` 映射到 **[0,1]** 之间，而不是 `[0, m-1]`。这样做的好处是：

- 数学上更方便处理（概率密度、分布函数等在区间 [0,1] 上有标准形式）；
- 更利于后续使用数学模型推导估计公式（例如 `E[min] = 1/(n+1)` 等）。

------

### 公式解释：

#### `h′(x) = h(x) / (m - 1)`

这是归一化公式，将哈希值从区间 `[0, m-1]` 映射到 `[0, 1]`，即：

- `h(x)` 是原始哈希值；
- `m` 是哈希函数的输出范围长度；
- `h′(x)` 是归一化后的值。

这个公式确保：

- 如果 `h(x) = 0`，那么 `h′(x) = 0`；
- 如果 `h(x) = m - 1`，那么 `h′(x) = 1`；
- 所以 `h′(x)` 的值总在 `[0,1]` 区间内。

------

### 图示解释：

图中显示的是一个从 `0` 到 `1` 的灰色三角形区域，对应 `h′(x)` 的值域。

- 顶部的 `h′(x)` 显示这是我们计算/关注的值；
- 横轴是归一化的哈希区间 `[0, 1]`；
- 蓝色底部强调仍然是**追踪最小值**。

------

### 总结：

这张幻灯片的关键点是：**为了后续更简洁地推导数学公式，我们将哈希值归一化到 [0,1] 区间。**

这个操作在很多基数估计算法（如 MinCount、HyperLogLog）中是非常常见的步骤，有助于构建与概率分布相关的估计方法。

------

需要我进一步说明归一化后如何用最小值估计集合大小吗？或者推导它的期望和估计公式？